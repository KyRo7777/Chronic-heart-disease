# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16OdCL45lxR2PiujoyHLbv0BKKEciC28M
"""

import pandas as pd # Import pandas for data manipulation
import numpy as np # Import numpy for numerical operations
from sklearn.linear_model import LogisticRegression # Import LogisticRegression for classification
from sklearn.model_selection import train_test_split # Import train_test_split for splitting data
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # Import metrics for model evaluation

# Define the column names for the dataset
columns = ['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke',
           'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD']

# Load data from framingham.csv locally from the Colab environment
# IMPORTANT: Ensure the 'framingham.csv' file is uploaded to your current Colab session.
data = pd.read_csv('framingham.csv', na_values='NA')
data.columns = columns # Assign the defined column names to the DataFrame

data = data.dropna() # Drop rows with any missing values

X = data.drop('TenYearCHD', axis=1) # Features (all columns except 'TenYearCHD')
y = data['TenYearCHD'] # Target variable ('TenYearCHD')

# Split the data into training and testing sets (75% train, 25% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

model = LogisticRegression(max_iter=5000) # Initialize Logistic Regression model with increased max_iter
model.fit(X_train, y_train) # Train the model using the training data

y_pred = model.predict(X_test) # Make predictions on the test set

# Evaluate the model's performance
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Calculate feature importance based on model coefficients
feature_importance = pd.Series(model.coef_[0], index=X.columns)
print("Top Features:\n", feature_importance.abs().sort_values(ascending=False).head(10))

# 1. Mount Google Drive
# This will prompt you to authorize Colab to access your Google Drive files.
from google.colab import drive
drive.mount('/content/drive')

print("Google Drive mounted successfully!")

# 2. Copy the framingham.csv file to Google Drive (Run this ONLY ONCE after initial upload)
# Make sure the 'framingham.csv' file is currently in '/content/' before running this.
# You can choose any path in your Google Drive, for example, a folder named 'Colab Notebooks/datasets'.

import os
import shutil

# Define the target directory in your Google Drive
drive_path = '/content/drive/MyDrive/Colab Notebooks/datasets'

# Create the directory if it doesn't exist
os.makedirs(drive_path, exist_ok=True)

# Source path where the file is currently located in Colab session
source_path = '/content/framingham.csv'

# Destination path in Google Drive
destination_path = os.path.join(drive_path, 'framingham.csv')

if os.path.exists(source_path):
    shutil.copy(source_path, destination_path)
    print(f"'framingham.csv' copied to {destination_path}")
else:
    print(f"'{source_path}' not found. Please ensure you have uploaded 'framingham.csv' to the current session or check the source path.")

# Verify the file is in Drive
if os.path.exists(destination_path):
    print("File successfully found in Google Drive.")
else:
    print("File not found in Google Drive. Please check the copying process.")

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

columns = ['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke',
           'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD']

# Load data from framingham.csv, now from Google Drive
# IMPORTANT: Make sure you have mounted Google Drive and copied the file there first.
# Update the path if you chose a different location in your Drive.
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/framingham.csv', na_values='NA')
data.columns = columns

data = data.dropna()

X = data.drop('TenYearCHD', axis=1)
y = data['TenYearCHD']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

model = LogisticRegression(max_iter=5000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

feature_importance = pd.Series(model.coef_[0], index=X.columns)
print("Top Features:\n", feature_importance.abs().sort_values(ascending=False).head(10))

y_pred_proba = model.predict_proba(X_test)[:, 1] # Get predicted probabilities for the positive class (class 1)
print("Predicted probabilities for TenYearCHD (class 1):\n", y_pred_proba[:10]) # Display the first 10 probabilities

X_test_with_proba = X_test.copy() # Create a copy of the test features DataFrame
X_test_with_proba['Predicted_Probability_CHD'] = y_pred_proba # Add predicted probabilities as a new column
print("DataFrame with X_test features and predicted probabilities (first 5 rows):\n", X_test_with_proba.head()) # Display the head of the new DataFrame

import matplotlib.pyplot as plt # Import matplotlib for plotting

print("Matplotlib imported successfully.")

# Define a list of selected features for potential analysis or plotting
selected_features = ['age', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']

# Define a dictionary to rename features for better readability in plots
feature_renaming_map = {
    'age': 'Age',
    'education': 'Education Level',
    'currentSmoker': 'Current Smoker',
    'cigsPerDay': 'Cigarettes per Day',
    'BPMeds': 'Blood pressure medicine',
    'prevalentStroke': 'Prevalent stroke',
    'prevalentHyp': 'Prevalent Hypertension',
    'diabetes': 'Diabetes',
    'totChol': 'Total Cholesterol',
    'sysBP': 'Systolic Blood Pressure',
    'diaBP': 'Diabetic Blood pressure',
    'BMI': 'Body Mass Index (BMI)',
    'heartRate': 'Heart Rate',
    'glucose': 'Glucose Level',
    'TenYearCHD': 'Heart Attack'
}

print("Selected features:", selected_features)
print("Feature renaming map:", feature_renaming_map)

# Update the list of specific features to be plotted
specific_features_to_plot = ['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP']
print("Updated specific features to plot:", specific_features_to_plot)

for feature in specific_features_to_plot:
    plt.figure(figsize=(8, 6)) # Create a new figure for each plot
    # Create a scatter plot of the feature against predicted probability
    plt.scatter(X_test_with_proba[feature], X_test_with_proba['Predicted_Probability_CHD'], alpha=0.6)
    # Set x-axis label using the renamed feature or original name
    plt.xlabel(feature_renaming_map.get(feature, feature))
    # Set y-axis label using the renamed 'TenYearCHD' label
    plt.ylabel('Predicted Probability of ' + feature_renaming_map['TenYearCHD'])
    # Set plot title using renamed feature and 'TenYearCHD' labels
    plt.title(f'{feature_renaming_map.get(feature, feature)} vs. Predicted Probability of {feature_renaming_map["TenYearCHD"]}')
    plt.grid(True) # Add a grid for better readability
    plt.show() # Display the plot

print("Scatter plots generated for updated selected features against Predicted Probability of Heart Attack.")